#################################
########  Folder 0  ############
device:  cuda:0
Namespace(batchsize=32, beta1=0.5, dataroot='../../../dataset', dataset='ecg', device='gpu', folder=0, gpu_ids=[0], isize=128, istest=True, lr=0.0001, model='beatgan', n_aug=0, name='beatgan/ecg', nc=1, ndf=54, ndfs=32, ngf=64, ngfs=32, ngpu=1, niter=100, nz=50, outf='./output', print_freq=100, threshold=0.003, w_adv=1, workers=1)

############ signal dataset ############
train_s data size:(62436, 1, 320)
val_s data size:(8025, 1, 320)
test_s N data size:(17343, 1, 320)
test_s S data size:(2723, 1, 320)
test_s V data size:(6307, 1, 320)
test_s F data size:(721, 1, 320)
test_s Q data size:(13, 1, 320)

############ frequency dataset ############
train_f data size:(62436, 1, 128, 128)
val_f data size:(8025, 1, 128, 128)
test_f N data size:(17343, 1, 128, 128)
test_f S data size:(2723, 1, 128, 128)
test_f V data size:(6307, 1, 128, 128)
test_f F data size:(721, 1, 128, 128)
test_f Q data size:(13, 1, 128, 128)
load data success!!!
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/network.py:25: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  torch.nn.init.xavier_uniform(mod.weight)
signal_encoder.main.0.weight
signal_encoder.main.2.weight
signal_encoder.main.3.weight
signal_encoder.main.3.bias
signal_encoder.main.3.running_mean
signal_encoder.main.3.running_var
signal_encoder.main.3.num_batches_tracked
signal_encoder.main.5.weight
signal_encoder.main.6.weight
signal_encoder.main.6.bias
signal_encoder.main.6.running_mean
signal_encoder.main.6.running_var
signal_encoder.main.6.num_batches_tracked
signal_encoder.main.8.weight
signal_encoder.main.9.weight
signal_encoder.main.9.bias
signal_encoder.main.9.running_mean
signal_encoder.main.9.running_var
signal_encoder.main.9.num_batches_tracked
signal_encoder.main.11.weight
signal_encoder.main.12.weight
signal_encoder.main.12.bias
signal_encoder.main.12.running_mean
signal_encoder.main.12.running_var
signal_encoder.main.12.num_batches_tracked
signal_encoder.main.14.weight
freq_2d_encoder.main.0.weight
freq_2d_encoder.main.2.weight
freq_2d_encoder.main.3.weight
freq_2d_encoder.main.3.bias
freq_2d_encoder.main.3.running_mean
freq_2d_encoder.main.3.running_var
freq_2d_encoder.main.3.num_batches_tracked
freq_2d_encoder.main.5.weight
freq_2d_encoder.main.6.weight
freq_2d_encoder.main.6.bias
freq_2d_encoder.main.6.running_mean
freq_2d_encoder.main.6.running_var
freq_2d_encoder.main.6.num_batches_tracked
freq_2d_encoder.main.8.weight
freq_2d_encoder.main.9.weight
freq_2d_encoder.main.9.bias
freq_2d_encoder.main.9.running_mean
freq_2d_encoder.main.9.running_var
freq_2d_encoder.main.9.num_batches_tracked
freq_2d_encoder.main.11.weight
freq_2d_encoder.main.12.weight
freq_2d_encoder.main.12.bias
freq_2d_encoder.main.12.running_mean
freq_2d_encoder.main.12.running_var
freq_2d_encoder.main.12.num_batches_tracked
freq_2d_encoder.main.14.weight
linear_s.weight
linear_s.bias
linear_f.weight
linear_f.bias
linear1.weight
linear1.bias
linear2.weight
linear2.bias
linear3.weight
linear3.bias
linear4.weight
linear4.bias
tf.transformer_encoder.layers.0.self_attn.in_proj_weight
tf.transformer_encoder.layers.0.self_attn.in_proj_bias
tf.transformer_encoder.layers.0.self_attn.out_proj.weight
tf.transformer_encoder.layers.0.self_attn.out_proj.bias
tf.transformer_encoder.layers.0.linear1.weight
tf.transformer_encoder.layers.0.linear1.bias
tf.transformer_encoder.layers.0.linear2.weight
tf.transformer_encoder.layers.0.linear2.bias
tf.transformer_encoder.layers.0.norm1.weight
tf.transformer_encoder.layers.0.norm1.bias
tf.transformer_encoder.layers.0.norm2.weight
tf.transformer_encoder.layers.0.norm2.bias
tf.transformer_encoder.layers.1.self_attn.in_proj_weight
tf.transformer_encoder.layers.1.self_attn.in_proj_bias
tf.transformer_encoder.layers.1.self_attn.out_proj.weight
tf.transformer_encoder.layers.1.self_attn.out_proj.bias
tf.transformer_encoder.layers.1.linear1.weight
tf.transformer_encoder.layers.1.linear1.bias
tf.transformer_encoder.layers.1.linear2.weight
tf.transformer_encoder.layers.1.linear2.bias
tf.transformer_encoder.layers.1.norm1.weight
tf.transformer_encoder.layers.1.norm1.bias
tf.transformer_encoder.layers.1.norm2.weight
tf.transformer_encoder.layers.1.norm2.bias
tf.transformer_encoder.layers.2.self_attn.in_proj_weight
tf.transformer_encoder.layers.2.self_attn.in_proj_bias
tf.transformer_encoder.layers.2.self_attn.out_proj.weight
tf.transformer_encoder.layers.2.self_attn.out_proj.bias
tf.transformer_encoder.layers.2.linear1.weight
tf.transformer_encoder.layers.2.linear1.bias
tf.transformer_encoder.layers.2.linear2.weight
tf.transformer_encoder.layers.2.linear2.bias
tf.transformer_encoder.layers.2.norm1.weight
tf.transformer_encoder.layers.2.norm1.bias
tf.transformer_encoder.layers.2.norm2.weight
tf.transformer_encoder.layers.2.norm2.bias
signal_decoder.main.0.weight
signal_decoder.main.1.weight
signal_decoder.main.1.bias
signal_decoder.main.1.running_mean
signal_decoder.main.1.running_var
signal_decoder.main.1.num_batches_tracked
signal_decoder.main.3.weight
signal_decoder.main.4.weight
signal_decoder.main.4.bias
signal_decoder.main.4.running_mean
signal_decoder.main.4.running_var
signal_decoder.main.4.num_batches_tracked
signal_decoder.main.6.weight
signal_decoder.main.7.weight
signal_decoder.main.7.bias
signal_decoder.main.7.running_mean
signal_decoder.main.7.running_var
signal_decoder.main.7.num_batches_tracked
signal_decoder.main.9.weight
signal_decoder.main.10.weight
signal_decoder.main.10.bias
signal_decoder.main.10.running_mean
signal_decoder.main.10.running_var
signal_decoder.main.10.num_batches_tracked
signal_decoder.main.12.weight
signal_decoder.main.13.weight
signal_decoder.main.13.bias
signal_decoder.main.13.running_mean
signal_decoder.main.13.running_var
signal_decoder.main.13.num_batches_tracked
signal_decoder.main.15.weight
tensor([[ 0.0312],
        [-0.1831],
        [ 0.1998],
        [-0.0401],
        [-0.1542],
        [ 0.0564],
        [ 0.0662],
        [-0.1920],
        [ 0.1239],
        [ 0.1267],
        [-0.2125],
        [-0.1373],
        [-0.1159],
        [ 0.0095],
        [-0.2032],
        [-0.1235],
        [-0.1722],
        [ 0.0755],
        [ 0.1457],
        [ 0.1544],
        [ 0.0078],
        [-0.1225],
        [-0.0270],
        [-0.2077],
        [-0.1812],
        [ 0.0801],
        [ 0.0979],
        [ 0.1775],
        [ 0.0052],
        [-0.1293],
        [ 0.1136],
        [-0.1626],
        [-0.0515],
        [-0.0371],
        [-0.0527],
        [ 0.0614],
        [-0.0650],
        [-0.0346],
        [ 0.1491],
        [ 0.1362],
        [ 0.1043],
        [ 0.0499],
        [-0.1526],
        [ 0.1770],
        [-0.1649],
        [-0.0005],
        [-0.0006],
        [-0.0871],
        [-0.1206],
        [-0.1918],
        [ 0.0802],
        [-0.1355],
        [-0.2092],
        [ 0.0981],
        [-0.1540],
        [-0.0609],
        [ 0.0376],
        [-0.1196],
        [-0.1927],
        [ 0.2069],
        [-0.0063],
        [ 0.0092],
        [-0.0879],
        [ 0.0526],
        [ 0.1367],
        [ 0.2156],
        [ 0.1271],
        [ 0.0718],
        [-0.0665],
        [ 0.0744],
        [-0.0965],
        [ 0.0032],
        [-0.1599],
        [ 0.1465],
        [-0.1235],
        [-0.0497],
        [-0.0198],
        [-0.1498],
        [-0.1005],
        [-0.2126],
        [ 0.0183],
        [ 0.0050],
        [-0.0956],
        [ 0.1139],
        [ 0.0317],
        [ 0.2080],
        [ 0.2036],
        [ 0.0027],
        [-0.1940],
        [-0.1684],
        [-0.1539],
        [ 0.0229],
        [ 0.0704],
        [ 0.0576],
        [ 0.1255],
        [-0.1729],
        [ 0.0165],
        [-0.1300],
        [-0.1534],
        [ 0.1449],
        [ 0.2071],
        [ 0.2140],
        [-0.1462],
        [ 0.0587],
        [-0.0845],
        [ 0.2153],
        [-0.1375],
        [ 0.2055],
        [ 0.1935],
        [ 0.0806],
        [ 0.0393],
        [ 0.0265],
        [-0.0271],
        [ 0.1846],
        [-0.1287],
        [-0.1800],
        [-0.0003],
        [ 0.1780],
        [ 0.1319],
        [ 0.1331],
        [ 0.0159],
        [ 0.1375],
        [ 0.0762],
        [-0.0378],
        [-0.2066],
        [ 0.0055],
        [ 0.0251],
        [-0.1004]], device='cuda:0') original signal
tensor([[-0.0462],
        [ 0.0492],
        [-0.0634],
        [-0.0649],
        [-0.0699],
        [ 0.0508],
        [ 0.0369],
        [-0.0804],
        [-0.0725],
        [ 0.0289],
        [ 0.0409],
        [ 0.0079],
        [ 0.0451],
        [ 0.0456],
        [ 0.0061],
        [ 0.0071],
        [-0.0503],
        [-0.0796],
        [ 0.0555],
        [ 0.0538],
        [-0.0666],
        [ 0.0394],
        [-0.0726],
        [-0.0657],
        [-0.0506],
        [ 0.0498],
        [ 0.0469],
        [ 0.0070],
        [-0.0760],
        [-0.0814],
        [-0.0737],
        [-0.0774],
        [-0.0564],
        [-0.0753],
        [-0.0648],
        [ 0.0077],
        [ 0.0067],
        [ 0.0042],
        [-0.0756],
        [-0.0624],
        [ 0.0391],
        [-0.0727],
        [-0.0658],
        [ 0.0428],
        [ 0.0420],
        [ 0.0067],
        [-0.0672],
        [-0.0776],
        [-0.0785],
        [-0.0788],
        [-0.0507],
        [-0.0677],
        [ 0.0457],
        [ 0.0525],
        [ 0.0077],
        [ 0.0492],
        [-0.0754],
        [ 0.0304],
        [ 0.0146],
        [ 0.0062],
        [-0.0614],
        [ 0.0470],
        [ 0.0397],
        [ 0.0512],
        [-0.0750],
        [ 0.0524],
        [-0.0733],
        [ 0.0406],
        [-0.0652],
        [ 0.0064],
        [ 0.0497],
        [ 0.0479],
        [-0.0608],
        [ 0.0506],
        [ 0.0079],
        [ 0.0344],
        [ 0.0443],
        [-0.0767],
        [-0.0736],
        [ 0.0483],
        [ 0.0528],
        [ 0.0489],
        [ 0.0159],
        [ 0.0433],
        [-0.0797],
        [-0.0642],
        [ 0.0066],
        [-0.0441],
        [-0.0650],
        [ 0.0510],
        [-0.0727],
        [ 0.0363],
        [ 0.0072],
        [ 0.0498],
        [-0.0692],
        [ 0.0455],
        [-0.0596],
        [-0.0586],
        [-0.0751],
        [-0.0549],
        [ 0.0488],
        [ 0.0373],
        [ 0.0447],
        [ 0.0088],
        [ 0.0480],
        [ 0.0190],
        [ 0.0299],
        [-0.0732],
        [ 0.0498],
        [ 0.0530],
        [ 0.0081],
        [ 0.0525],
        [ 0.0471],
        [ 0.0078],
        [ 0.0489],
        [-0.0613],
        [ 0.0481],
        [-0.0691],
        [-0.0454],
        [ 0.0231],
        [-0.0324],
        [-0.0773],
        [ 0.0470],
        [-0.0564],
        [ 0.0316],
        [ 0.0213],
        [ 0.0079],
        [ 0.0455]], device='cuda:0') after signal
tensor([[ 0.0275,  0.0458,  0.0536, -0.0532],
        [-0.0761, -0.0061, -0.0334, -0.0788],
        [ 0.0074,  0.0511, -0.0035, -0.0638],
        [ 0.0182, -0.0270,  0.0059,  0.0274]], device='cuda:0') before freq
tensor([[ 0.0099,  0.1211,  0.0122,  0.0470],
        [-0.0884,  0.0369, -0.0336, -0.0467],
        [ 0.0347, -0.0717, -0.0996, -0.0153],
        [ 0.0074,  0.0103, -0.0498,  0.1064]], device='cuda:0') after freq
tensor([ 0.0239,  0.2660, -0.0212,  0.1045], device='cuda:0') before signal
tensor([ 0.0187,  0.2621, -0.0236,  0.1031], device='cuda:0') after signal

model_device: cuda:0 

################  Eval  ##################
############   Analysis   #############
############   Threshold:0.003   #############
*********  Type:S  *************
TP:2545
FP:6487
TN:10856
FN:178
Accuracy:0.6678461078441145
Precision/ppv:0.2817759078830824
sensitivity/Recall:0.9346309217774513
specificity:0.625958600011532
F1:0.43300723096554655
*********  Type:V  *************
TP:6296
FP:6487
TN:10856
FN:11
Accuracy:0.7252431289640592
Precision/ppv:0.4925291402644137
sensitivity/Recall:0.9982559061360393
specificity:0.625958600011532
F1:0.6596123624934521
*********  Type:F  *************
TP:621
FP:6487
TN:10856
FN:100
Accuracy:0.6353520814880426
Precision/ppv:0.0873663477771525
sensitivity/Recall:0.8613037447988904
specificity:0.625958600011532
F1:0.15864095031293907
*********  Type:Q  *************
TP:13
FP:6487
TN:10856
FN:0
Accuracy:0.6262387646923254
Precision/ppv:0.002
sensitivity/Recall:1.0
specificity:0.625958600011532
F1:0.003992015968063872
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
/data/haenim/lab/trained_linear_encoder_real/experiments/ecg/plotUtil.py:196: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots(2, 1, sharex=True,figsize=(6, 6),gridspec_kw = {'height_ratios':[6,1]})
#############################
########  Result  ###########
ap:0.8872176226160273
auc:0.9278866358202575
best th:0.00594186270609498 --> best f1:0.7883009641555565
